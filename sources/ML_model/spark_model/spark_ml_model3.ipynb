{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SPARK_ML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/Michavillson/Documents/PROJECTS/DS340W-Group10-FA19/sources/ML_model/output/ml_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+-----------+-------------------+----+----+-----+-------+\n|        avo|                cur|cell|mark|ideas|  valid|\n+-----------+-------------------+----+----+-----+-------+\n| 0.24699525|0.18017438579760167| C46| M03|    0|0.22644|\n|0.248117075|0.18017438579760167| C46| M03|   92|0.22644|\n| 0.24817445|0.18017438579760167| C46| M03|    0|0.22644|\n|0.247927175|0.18017438579760167| C46| M03|    0|0.22644|\n|0.248311925|0.18017438579760167| C46| M03|    0|0.22644|\n+-----------+-------------------+----+----+-----+-------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "df = spark.read.format(\"com.databricks.spark.csv\").options(header=\"true\", inferschema=\"true\").load(DATA_PATH)\n",
    "df.show(5, True)\n",
    "# df.printSchema()\n",
    "# df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy(df,categoricalCols,continuousCols,labelCol): \n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "    from pyspark.sql.functions import col\n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categoricalCols ]\n",
    "    # default setting: dropLast=True\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers ]\n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + continuousCols, outputCol=\"features\")\n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "    data = data.withColumn('label',col(labelCol))\n",
    "    return data.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+--------------------+-------+\n|            features|  label|\n+--------------------+-------+\n|(110,[1,11,108,10...|0.22644|\n+--------------------+-------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "transformed_dummy = get_dummy(df, [\"cell\", \"mark\", \"ideas\"], [\"avo\", \"cur\"], \"valid\")\n",
    "transformed_dummy.show(1)\n",
    "\n",
    "# transformed_df = transData(df)\n",
    "# transformed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+--------------------+-------+--------------------+\n|            features|  label|     indexedFeatures|\n+--------------------+-------+--------------------+\n|(110,[1,11,108,10...|0.22644|(110,[1,11,108,10...|\n|(110,[1,104,108,1...|0.22644|(110,[1,104,108,1...|\n|(110,[1,11,108,10...|0.22644|(110,[1,11,108,10...|\n|(110,[1,11,108,10...|0.22644|(110,[1,11,108,10...|\n|(110,[1,11,108,10...|0.22644|(110,[1,11,108,10...|\n+--------------------+-------+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=100).fit(transformed_dummy)\n",
    "data = featureIndexer.transform(transformed_dummy)\n",
    "data.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "728568\n485892\n"
    }
   ],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = GBTRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+--------------------+------------+--------------------+\n|            features|       label|          prediction|\n+--------------------+------------+--------------------+\n|(110,[0,10,11,108...|         0.0| 0.07849030586887516|\n|(110,[0,10,11,108...|         0.0| 0.07849030586887516|\n|(110,[0,10,11,108...|         0.0| 0.07849030586887516|\n|(110,[0,10,11,108...|         0.0| 0.07849030586887516|\n|(110,[0,10,11,108...|0.0174466129|0.013794805312973921|\n+--------------------+------------+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.7679807436337086\n"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}